# Proyecto: Plataforma Inteligente para Gesti√≥n de Modelos de IA y Recuperaci√≥n de Informaci√≥n

## Descripci√≥n General
Este proyecto es una aplicaci√≥n  dise√±ada para potenciar el uso de Modelos de Lenguaje Extenso (LLMs) locales y en la nube, incluyendo OpenAI y Grok, integrados con un sistema de Recuperaci√≥n de Informaci√≥n (RAG). Ofrece una interfaz amigable desarrollada en **Streamlit**, con capacidades avanzadas para:

- Gestionar modelos de IA mediante un selector din√°mico.
- Incorporar bases de datos vectoriales para almacenamiento y recuperaci√≥n eficiente de informaci√≥n.
- Garantizar seguridad y facilidad de uso con tunelizaci√≥n segura y configuraci√≥n personalizable.

La aplicaci√≥n combina potencia y simplicidad para habilitar a desarrolladores, investigadores y usuarios finales en la creaci√≥n de soluciones basadas en inteligencia artificial.




## Caracter√≠sticas Principales

1. **Framework Principal**: 
   - Se utiliza **Python puro** junto con **Streamlit** para la interfaz de usuario amigable.

2. **Bases de Datos**:
   - **Firebase**: Para almacenar validaciones de correos electr√≥nicos en la p√°gina de cuentas.
   - **Chromadb**: Para bases de datos vectoriales que almacenan embeddings representados como vectores num√©ricos.

3. **Modelos**:
   - **Embeddings de OpenAI**: Base de datos vectorial para embeddings generados por OpenAI.
   - **Embeddings de Ollama**: Embeddings generados por modelos locales de Ollama.

4. üîí**Tunelizaci√≥n Segura**:
   ‚úÖ **Ngrok**: Creaci√≥n de un t√∫nel seguro (puerto `4040`) para compartir la aplicaci√≥n sin vulnerabilidades.

5. **Selector de Modelos**:
   - Opci√≥n para elegir entre:
     ‚≠ê OpenAI
     ‚≠ê Grok
     ‚≠ê Modelos locales personalizados.

6. **Personalizaci√≥n**:
   ‚≠ê Actualizaci√≥n sencilla del token de Ngrok en `ngrok.yml`.
   ‚≠ê Selecci√≥n de modelo predeterminado desde el archivo `.env`.


1. Configurar variables de entorno:
   - Editar archivo nano `.env`:
     ```env
     MODEL_LIST=llama3.2,llama3,mistral,tinyllama,phi3,llama2,brxce/stable-diffusion-prompt-generator,gemma2:2b
     ```

2. Configurar Ngrok:
   - Editar el archivo `ngrok.yml` para incluir tu token:
   - Editar archivo nano `ngrok.yml`:
     ```yaml
     authtoken: YOUR_NGROK_TOKEN
     ```

